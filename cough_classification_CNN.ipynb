{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "cough_classification_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH4F7rQ7QI8m",
        "colab_type": "text"
      },
      "source": [
        "Librosa - example for reading audio files - .wav "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stqp12LC8T0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Research references:\n",
        "#1) Dry/wet cough classification: https://link.springer.com/article/10.1007/s10439-013-0741-6\n",
        "#2) Pneumonia classification: https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6987276\n",
        "#3) https://espace.library.uq.edu.au/data/UQ_344963/s41943203_phd_submission.pdf?Expires=1585601065&Key-Pair-Id=APKAJKNBJ4MJBJNC6NLQ&Signature=Lnpf6wT8rkozSh9av7U9nGuC7WAH6KuI2Cj3Y7G366gkGlh8D-Ie1Kc~TyBAUu~uMsVltleJcSv3p6TCm6HdFnhpyoTgLcYh6eFfvQwIUqbk1Bf4JZldgB~BDKUOwY1G0pA-HoKjvIAu3avO98SMO35upakm9OEBByd4nC9aXsjKRThd6bTpq1qIuuD9gh1l5FaM6hNRB0c2lCf4Q3adx7C3FW0NMwdWhcuF45A9f~dO3zTWWSQamoo5Otc-PHMMt96TetNcML~jy9ghgJeCPY6DJLUIwQAt03fENBluS~TjTJ17WD~n51xiRofb94fEJHoRHh0d-430LLwr7BX4IA__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1m0Zx8S9Cas",
        "colab_type": "code",
        "outputId": "a242b48f-3cce-4711-c0e6-68206e54e474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "!pip install pydub"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/79/db/eaf620b73a1eec3c8c6f8f5b0b236a50f9da88ad57802154b7ba7664d0b8/pydub-0.23.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.23.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj_b7qHhVAOe",
        "colab_type": "code",
        "outputId": "d9c7faeb-8d9c-42bd-f03c-633c088cf48b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "!pip install python_speech_features"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python_speech_features\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-cp36-none-any.whl size=5887 sha256=73df421222b8b0e6286e6f1f0c9b44cdd305eb2f91d07b7f02ff6afe61aff7b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3-nMncBVLHh",
        "colab_type": "code",
        "outputId": "8fa31b71-75f7-4828-c2dd-b9fdd3c6428d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "!pip install pysptk"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pysptk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/25/4ea0932fbf0f1db42934b85011c1c825bcf57055ecde7e511f05e9fb9197/pysptk-0.1.18.tar.gz (419kB)\n",
            "\r\u001b[K     |▉                               | 10kB 16.6MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20kB 6.2MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30kB 8.5MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40kB 5.4MB/s eta 0:00:01\r\u001b[K     |████                            | 51kB 6.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 61kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 71kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 81kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 92kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 102kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 112kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 122kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 133kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 143kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 153kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 163kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 174kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 184kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 194kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 204kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 215kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 225kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 235kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 245kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 256kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 266kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 276kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 286kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 296kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 307kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 317kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 327kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 337kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 348kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 358kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 368kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 378kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 389kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 399kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 409kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 419kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pysptk) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pysptk) (1.12.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from pysptk) (4.4.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->pysptk) (1.18.2)\n",
            "Building wheels for collected packages: pysptk\n",
            "  Building wheel for pysptk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysptk: filename=pysptk-0.1.18-cp36-cp36m-linux_x86_64.whl size=949957 sha256=b0f1aba1a668643f4d6dfd7a351d24dd61164a664111e27d999d911bdb12eb74\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/96/d2/a163240019c59504402fab713af259026af81a99dea943404a\n",
            "Successfully built pysptk\n",
            "Installing collected packages: pysptk\n",
            "Successfully installed pysptk-0.1.18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie785avw8T06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "#import pywt #wavelets\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "from pydub.utils import mediainfo\n",
        "from pydub.playback import play\n",
        "import matplotlib.pyplot as plt\n",
        "#import seaborn as sn\n",
        "import python_speech_features as spe_feats\n",
        "import pandas as pd\n",
        "from scipy.stats import kurtosis, skew\n",
        "from scipy.signal import lfilter\n",
        "import librosa\n",
        "import pysptk\n",
        "import math\n",
        "import sys\n",
        "import random\n",
        "random.seed(1)\n",
        "#settings\n",
        "import config\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1n9GnYA8T1F",
        "colab_type": "text"
      },
      "source": [
        "## Reading recordings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3txTjKc8T1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_s=[]\n",
        "all_label=[]\n",
        "all_id=[]\n",
        "all_fs=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VttyEwI3xhWe",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdjMzqVR8T1P",
        "colab_type": "code",
        "outputId": "ddb3d18f-ef0c-4243-c386-7c656579984e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Read wav data set\n",
        "\n",
        "if config.featExtr_skip is False:\n",
        "    print(\"Readings wavs...\")\n",
        "\n",
        "    #only list files in FOLDER_PATH directory\n",
        "    wav_files = [f for f in os.listdir(config.FOLDER_PATH) if os.path.isfile(os.path.join(config.FOLDER_PATH, f))]\n",
        "    for file_name in wav_files:\n",
        "    \n",
        "        fname_noExt = os.path.splitext(file_name)[0] #file name without extension\n",
        "    \n",
        "        #full path file name\n",
        "        full_fname = config.FOLDER_PATH+file_name\n",
        "        print(full_fname)\n",
        "    \n",
        "        # load audio\n",
        "        s = AudioSegment.from_wav(full_fname)\n",
        "        print(full_fname)\n",
        "        all_s.append(s)\n",
        "        #sampling rate:\n",
        "        info = mediainfo(full_fname)\n",
        "        fs = float(info['sample_rate'])\n",
        "        all_fs.append(fs)\n",
        "    \n",
        "        #get ID of recording\n",
        "        ID = fname_noExt.split('-')[-2] #for the current type of naming\n",
        "        #print(file_name)\n",
        "        #print(ID)\n",
        "        all_id.append(ID)\n",
        "        words = ['covid', 'suspect', 'healthy']\n",
        "        #for l in words:\n",
        "         #   if l in fname_noExt:\n",
        "          #      label = l\n",
        "        #get label\n",
        "        label = fname_noExt.split('-')[-1] #for the current type of naming #Change this for updated data \n",
        "        #print(label)\n",
        "        all_label.append(label)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Readings wavs...\n",
            "data/YT_set/edited_wavs/edit_Wheezing Chest and Wet Cough 2-5905FxXz9dI-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Wheezing Chest and Wet Cough 2-5905FxXz9dI-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Coughing 46-dg-I9j76-t8-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Coughing 46-dg-I9j76-t8-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Coughing 14 - After work-1UDFq2InljM-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_Coughing 14 - After work-1UDFq2InljM-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_# 34 coughing up crap again-rkF_uMizqoc-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_# 34 coughing up crap again-rkF_uMizqoc-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_# 61 morning phlegmy cough...again-qfpJg179YNk-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_# 61 morning phlegmy cough...again-qfpJg179YNk-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Dry Afternoon Cough-6LK6yHtIung-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_Dry Afternoon Cough-6LK6yHtIung-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_November cold (wet coughing)-DYfjPnty2Ho-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_November cold (wet coughing)-DYfjPnty2Ho-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_DIST_Another Girl Coughing-iYxUHA-Pwsk-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_DIST_Another Girl Coughing-iYxUHA-Pwsk-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_More Allergy Coughing-NfKZNt25L-Q-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_More Allergy Coughing-NfKZNt25L-Q-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_Wet coughing-0QQxKN-KC1U-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Wet coughing-0QQxKN-KC1U-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Man Coughing Sound - Wet Cough Sound Effect-q6WsoL3J8U8-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Man Coughing Sound - Wet Cough Sound Effect-q6WsoL3J8U8-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Spring Allergy Coughing-7Ez5Wc_esBg-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_Spring Allergy Coughing-7Ez5Wc_esBg-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_My deep wet cough-De4HdyocTHY-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_My deep wet cough-De4HdyocTHY-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Spring Cold Coughing 3-tZtJaS2ZtME-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_Spring Cold Coughing 3-tZtJaS2ZtME-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_Dry Early Morning Cough-XrpB4DTNQZw-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_Dry Early Morning Cough-XrpB4DTNQZw-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_Male bronchitis cough-IzPMbIll3LE-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Male bronchitis cough-IzPMbIll3LE-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Single wet cough-CTSLdNxN1cc-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Single wet cough-CTSLdNxN1cc-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Wet Throat Infection Cough-tfc5cXiXMDc-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Wet Throat Infection Cough-tfc5cXiXMDc-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Coughing 77-2Mw-s5jnqXU-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Coughing 77-2Mw-s5jnqXU-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_DIST_Coughing 79-h2FLCKMcEX0-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_DIST_Coughing 79-h2FLCKMcEX0-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Coughing 51-LkxvBb2VXbs-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_Coughing 51-LkxvBb2VXbs-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_Residual Phlegmy Morning Coughing and Gagging-TK4CveeCWfY-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Residual Phlegmy Morning Coughing and Gagging-TK4CveeCWfY-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Dry Morning Cough turns Chesty and Barking.-ekqLlw-Xe68-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_Dry Morning Cough turns Chesty and Barking.-ekqLlw-Xe68-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_Spring Cold Coughing.-u2KMBD5-oCg-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_Spring Cold Coughing.-u2KMBD5-oCg-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_# 55 gaggy wet cough-ct3tHDfNKiQ-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_# 55 gaggy wet cough-ct3tHDfNKiQ-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Heavy cold and sore throat coughing.-NaOVmYoIjbs-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_Heavy cold and sore throat coughing.-NaOVmYoIjbs-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_# 60 coughing still (deep and wet cough)-jxYNLCYTwZQ-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_# 60 coughing still (deep and wet cough)-jxYNLCYTwZQ-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Spring Cold Coughing 2-AQOeIVbhFm4-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_Spring Cold Coughing 2-AQOeIVbhFm4-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_Coughing Woman Sound - Woman Cough Sound Effect-zjd4HrJbc8o-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_Coughing Woman Sound - Woman Cough Sound Effect-zjd4HrJbc8o-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_Cough Around the Clock!-4k0ziD0j5BI-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Cough Around the Clock!-4k0ziD0j5BI-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_# 31 night wet cough-Dc_aoUCqw2E-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_# 31 night wet cough-Dc_aoUCqw2E-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Dry Coughing Fit in the Afternoon.-A5s2ZgwQ1VM-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_Dry Coughing Fit in the Afternoon.-A5s2ZgwQ1VM-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_#64 coughing, allergies, singing lungs-CsDXlt7Ei1c-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_#64 coughing, allergies, singing lungs-CsDXlt7Ei1c-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_# 30 Chesty and wet cough-d2wkdrScerU-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_# 30 Chesty and wet cough-d2wkdrScerU-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Coughing 60-diuuEXKzNB8-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Coughing 60-diuuEXKzNB8-Wet.wav\n",
            "data/YT_set/edited_wavs/edit_Mid-morning Winter Coughing Fit-h-GtQfDCoaE-Dry.wav\n",
            "data/YT_set/edited_wavs/edit_Mid-morning Winter Coughing Fit-h-GtQfDCoaE-Dry.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVSYcKO2BhR8",
        "colab_type": "code",
        "outputId": "25bc995a-854f-492e-d191-49b09255053b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(wav_files) # Total 36 files uploaded "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFAzqvQW8T1Y",
        "colab_type": "text"
      },
      "source": [
        "Listening to some of the audios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBSlnhuYxOXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if config.featExtr_skip is False:\n",
        "    np.where(np.array(all_label)=='Dry')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6wIrNszxOLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if config.featExtr_skip is False:\n",
        "    np.where(np.array(all_label)=='Wet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGZPNaA38T1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if config.featExtr_skip is False:\n",
        "    np.where(np.array(all_label)=='suspect')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw2Gy7qT8T1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if config.featExtr_skip is False:\n",
        "    s=all_s[15]\n",
        "    s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7AMbOk78T1t",
        "colab_type": "text"
      },
      "source": [
        "## Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjONKlk53kZA",
        "colab_type": "code",
        "outputId": "8f077780-1c45-4704-ff8a-a673a48ac2ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "np.shape(all_label)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQZvLEiaJICZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_label #Fix this - should contain - healthy , covid, suspect - eventually classify suspect VS covid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT0xoIPI8T1u",
        "colab_type": "code",
        "outputId": "1c344caf-3a18-4295-933b-4567618750ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import featureExtractionFunctions as featExtrLib\n",
        "import pysptk\n",
        "\n",
        "if config.featExtr_skip is False:\n",
        "\n",
        "    feats = featExtrLib.feature_extraction_Step(all_s,all_id,all_label)\n",
        "    \n",
        "       \n",
        "#Lenght of all_s, all_id and all_label must be the same\n",
        "       #Lenght is 36, of a ll arguments "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n",
            "High-pass filtering...\n",
            "Computing features...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIivFH5V9T7m",
        "colab_type": "code",
        "outputId": "0f404833-1dc0-42af-9c23-42e821d444d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "feats.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4470, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK2O13YX8T11",
        "colab_type": "text"
      },
      "source": [
        "## Load  (or store) features "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNWjMyke8T12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feats_fname = 'feats_df.pkl'\n",
        "\n",
        "if config.featExtr_skip is False:\n",
        "    #Store feature df\n",
        "    feats.to_pickle(feats_fname)\n",
        "else:\n",
        "    #Load feature df\n",
        "    feats = pd.read_pickle(feats_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBIfO9G7OWyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "6f9547a4-69e0-43dd-84ed-5393b22e26d2"
      },
      "source": [
        "\n",
        "pandas2ri.activate()\n",
        "\n",
        "base = importr('base')\n",
        "# call an R function on a Pandas DataFrame\n",
        "base.summary(feats_fname)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/rpy2/robjects/vectors.py:927: UserWarning: R object inheriting from \"POSIXct\" but without attribute \"tzone\".\n",
            "  warnings.warn('R object inheriting from \"POSIXct\" but without '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1', 'character', 'character'], dtype='<U9')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM_uxal58T19",
        "colab_type": "text"
      },
      "source": [
        "## Pre-processing of features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIayUJ108T19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feats2 = featExtrLib.processingNaNvalues(feats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk4bLREC8T2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_dict = featExtrLib.createLabelDict_addLabel2df(feats2)\n",
        "mean_std_feats = featExtrLib.frame_mean_std_chunk_modeling (feats2,label_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiCuV5WMo3go",
        "colab_type": "code",
        "outputId": "f513fad7-0df6-46b9-c348-00f42b6a5ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mean_std_feats.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(465, 101)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBENHFc-8T2K",
        "colab_type": "text"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMxUbK2XHtox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = mean_std_feats.drop(['label','Id','subIdx'], 1).copy()\n",
        "y_train =  mean_std_feats['label'].copy()\n",
        "\n",
        "ID_train = mean_std_feats['Id']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5PY-NuVemmm",
        "colab_type": "code",
        "outputId": "c90987b4-1f30-4db2-9562-9ffb4d201c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "y_train #465"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      Dry\n",
              "1      Dry\n",
              "2      Dry\n",
              "3      Dry\n",
              "4      Dry\n",
              "      ... \n",
              "460    Dry\n",
              "461    Dry\n",
              "462    Dry\n",
              "463    Dry\n",
              "464    Dry\n",
              "Name: label, Length: 465, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tef6_iIJeEOg",
        "colab_type": "code",
        "outputId": "8b88766d-e639-4843-f356-b1aa26870cb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(465, 98)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-WCZejj8T2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import modelTrainingFunctions as modelTrainLib\n",
        "\n",
        "pred_probs = modelTrainLib.modelTraining(X_train,y_train,ID_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6HOrLmp8T2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_pred_probs = modelTrainLib.get_predClass_per_audio(pred_probs, label_dict)\n",
        "\n",
        "\n",
        "#Change here "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H_f9Rzt8T2c",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igPnYto-8T2d",
        "colab_type": "code",
        "outputId": "b87afd9c-c766-4a2c-8f25-b97cfe356810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "#Change script to multiclass labeling\n",
        "\n",
        "import classifEvaluationFunctions as evalLib\n",
        "evalLib.evaluation_Step(mean_pred_probs)\n",
        "    \n",
        "\n",
        "\n",
        "#Scores:\n",
        "#Accuracy: 0.583333\n",
        "#Precision: 0.583333\n",
        "#F1-score: 0.580420\n",
        "#Recall: 0.585714\n",
        "\n",
        "#Confusion matrix\n",
        "#pred_class  Dry  Wet  All\n",
        "#label                    \n",
        "#Dry           9    6   15\n",
        "#Wet           9   12   21\n",
        "#All          18   18   36"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores:\n",
            "Accuracy: 0.750000\n",
            "Precision: 0.750000\n",
            "F1-score: 0.748252\n",
            "Recall: 0.757143\n",
            "\n",
            "Confusion matrix\n",
            "pred_class  Dry  Wet  All\n",
            "label                    \n",
            "Dry          12    3   15\n",
            "Wet           6   15   21\n",
            "All          18   18   36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bgo_2IH6-01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Export the prediction model for SGD\n",
        "\n",
        "#After training export the trained model using pickle REf :https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/\n",
        "import pickle\n",
        "filename = \"/home/sap007/Master-Thesis/Streamlit Demo_LA/model_Dec2vec.sav\"\n",
        "pickle.dump(model,open(filename,'wb'))\n",
        "print(\"File exported\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CRkuVinhtcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = y_train.astype('category')\n",
        "y_train = y_train.cat.codes\n",
        "y_train.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgahgiIPFr7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import modelTrainingFunctions_CNN as modelTrainLib\n",
        "\n",
        "pred_probs = modelTrainLib.modelTraining(X_train,y_train,ID_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lUyripTFrl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.values()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDI12XVgNRA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title('Accuracy')\n",
        "plt.plot(history.history['acc'], label='train')\n",
        "plt.plot(history.history['val_acc'], label='test')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImlMdmqJFHO5",
        "colab_type": "code",
        "outputId": "5728b4c0-b230-40da-8fdb-24deb9c35ac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Evaluating the model on the training and testing set\n",
        "score = model.evaluate(xx_train, yy_train, verbose=0)\n",
        "print(\"Training Accuracy: {0:.2%}\".format(score[1]))\n",
        "score = model.evaluate(xx_test, yy_test, verbose=0)\n",
        "print(\"Testing Accuracy: {0:.2%}\".format(score[1]))\n",
        "\n",
        "\n",
        "#Training Accuracy: 95.97%\n",
        "#Testing Accuracy: 76.34%\n",
        "\n",
        "\n",
        "#Training Accuracy: 98.77%\n",
        "#Testing Accuracy: 72.14%\n",
        "\n",
        "\n",
        "#Training Accuracy: 92.58%\n",
        "#Testing Accuracy: 85.11%\n",
        "\n",
        "#Training Accuracy: 84.45%\n",
        "#Testing Accuracy: 82.98%\n",
        "\n",
        "#Training Accuracy: 82.54%\n",
        "#Testing Accuracy: 74.47%\n",
        "\n",
        "#Training Accuracy: 83.73%\n",
        "#Testing Accuracy: 80.85%\n",
        "\n",
        "\n",
        "#Training Accuracy: 84.45%\n",
        "#Testing Accuracy: 82.98%\n",
        "\n",
        "#Training Accuracy: 84.21%\n",
        "#Testing Accuracy: 82.98%\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 79.94%\n",
            "Testing Accuracy: 77.78%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54ok2ABWQqDZ",
        "colab_type": "text"
      },
      "source": [
        "Fine tune the parameters to improve classification accuracy - if not then refine the features used - perhaps add weightage somewhere - aim for atleast 80% accuracy "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjCCYSr7vqsq",
        "colab_type": "text"
      },
      "source": [
        "Generation 15 - Current best internal CV score: 0.7109589041095891\n",
        "\n",
        "Best pipeline: DecisionTreeClassifier(PolynomialFeatures(CombineDFs(input_matrix, input_matrix), degree=2, include_bias=False, interaction_only=False), criterion=entropy, max_depth=3, min_samples_leaf=18, min_samples_split=16)\n",
        "\n",
        "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
        "               disable_update_check=False, early_stop=None, generations=15,\n",
        "               max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
        "               mutation_rate=0.9, n_jobs=1, offspring_size=None,\n",
        "               periodic_checkpoint_folder=None, population_size=50,\n",
        "               random_state=42, scoring=None, subsample=1.0, template=None,\n",
        "               use_dask=False, verbosity=2, warm_start=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqfocG7WYYBO",
        "colab_type": "text"
      },
      "source": [
        "Sequence Modeling \n",
        "\n",
        "\n",
        "hi, i just wanted to mention, about the modeling of features using sequence models. the current super basic way that I used is modeling chunks of X consecutive frames (so far I used 10frames) computing their mean and standard deviation.\n",
        "3:05\n",
        "You can use maybe this function as model. It is within the featureExtractionFunctions.py script\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_9RJd_3YiDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}